{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13abec24",
   "metadata": {
    "id": "PxgHODPdFu5Q",
    "papermill": {
     "duration": 0.009044,
     "end_time": "2025-12-12T10:27:28.620592",
     "exception": false,
     "start_time": "2025-12-12T10:27:28.611548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0a5b19",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1765265964899,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "w8VtJbvb1Pis",
    "papermill": {
     "duration": 0.007249,
     "end_time": "2025-12-12T10:27:28.635452",
     "exception": false,
     "start_time": "2025-12-12T10:27:28.628203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0353c7fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:28.651141Z",
     "iopub.status.busy": "2025-12-12T10:27:28.650870Z",
     "iopub.status.idle": "2025-12-12T10:27:33.295998Z",
     "shell.execute_reply": "2025-12-12T10:27:33.295307Z"
    },
    "executionInfo": {
     "elapsed": 13752,
     "status": "ok",
     "timestamp": 1765265978653,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "C8K5C4PHFLmB",
    "outputId": "852597c1-55e4-49d1-eb10-cc6d0754f7b6",
    "papermill": {
     "duration": 4.654674,
     "end_time": "2025-12-12T10:27:33.297411",
     "exception": false,
     "start_time": "2025-12-12T10:27:28.642737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.2/963.2 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install musdb -q\n",
    "# !pip uninstall -y ffmpeg\n",
    "# !pip uninstall -y ffmpeg-python]\\[''']\n",
    "# !pip install -q ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6476d7ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:33.314644Z",
     "iopub.status.busy": "2025-12-12T10:27:33.314398Z",
     "iopub.status.idle": "2025-12-12T10:27:33.388758Z",
     "shell.execute_reply": "2025-12-12T10:27:33.388024Z"
    },
    "executionInfo": {
     "elapsed": 114,
     "status": "ok",
     "timestamp": 1765265978772,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "OkrgG8lXt8Bh",
    "papermill": {
     "duration": 0.08466,
     "end_time": "2025-12-12T10:27:33.390016",
     "exception": false,
     "start_time": "2025-12-12T10:27:33.305356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import musdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9f0fc0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:33.406561Z",
     "iopub.status.busy": "2025-12-12T10:27:33.406371Z",
     "iopub.status.idle": "2025-12-12T10:27:33.409666Z",
     "shell.execute_reply": "2025-12-12T10:27:33.408996Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1765265978789,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "-NsH9kP73yCT",
    "papermill": {
     "duration": 0.012958,
     "end_time": "2025-12-12T10:27:33.410824",
     "exception": false,
     "start_time": "2025-12-12T10:27:33.397866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://zenodo.org/records/1117372 - датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e764916b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:33.426442Z",
     "iopub.status.busy": "2025-12-12T10:27:33.426229Z",
     "iopub.status.idle": "2025-12-12T10:27:37.570809Z",
     "shell.execute_reply": "2025-12-12T10:27:37.570214Z"
    },
    "executionInfo": {
     "elapsed": 10396,
     "status": "ok",
     "timestamp": 1765265989188,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "H24ENSeGy2SK",
    "papermill": {
     "duration": 4.153952,
     "end_time": "2025-12-12T10:27:37.572162",
     "exception": false,
     "start_time": "2025-12-12T10:27:33.418210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import musdb\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "636a6cc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:37.589011Z",
     "iopub.status.busy": "2025-12-12T10:27:37.588691Z",
     "iopub.status.idle": "2025-12-12T10:27:37.591889Z",
     "shell.execute_reply": "2025-12-12T10:27:37.591351Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1765265989195,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "09HwK_0F7-x5",
    "papermill": {
     "duration": 0.012717,
     "end_time": "2025-12-12T10:27:37.592922",
     "exception": false,
     "start_time": "2025-12-12T10:27:37.580205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import stempeg\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd6a0359",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:37.609239Z",
     "iopub.status.busy": "2025-12-12T10:27:37.608597Z",
     "iopub.status.idle": "2025-12-12T10:27:37.617284Z",
     "shell.execute_reply": "2025-12-12T10:27:37.616737Z"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1765265989205,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "7wvzzfISFS6_",
    "outputId": "4d0c0562-a602-4166-c1d9-e379b9396f57",
    "papermill": {
     "duration": 0.017963,
     "end_time": "2025-12-12T10:27:37.618370",
     "exception": false,
     "start_time": "2025-12-12T10:27:37.600407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7875c4149f90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026f852f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:37.635136Z",
     "iopub.status.busy": "2025-12-12T10:27:37.634492Z",
     "iopub.status.idle": "2025-12-12T10:27:38.765127Z",
     "shell.execute_reply": "2025-12-12T10:27:38.764375Z"
    },
    "executionInfo": {
     "elapsed": 2436,
     "status": "ok",
     "timestamp": 1765265991641,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "rrkl2M7z1IN_",
    "papermill": {
     "duration": 1.140222,
     "end_time": "2025-12-12T10:27:38.766525",
     "exception": false,
     "start_time": "2025-12-12T10:27:37.626303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f62c3",
   "metadata": {
    "id": "CP-cxDTqFomz",
    "papermill": {
     "duration": 0.008446,
     "end_time": "2025-12-12T10:27:38.783198",
     "exception": false,
     "start_time": "2025-12-12T10:27:38.774752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Необходимые классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "132eaa12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:38.799655Z",
     "iopub.status.busy": "2025-12-12T10:27:38.799074Z",
     "iopub.status.idle": "2025-12-12T10:27:38.858216Z",
     "shell.execute_reply": "2025-12-12T10:27:38.857471Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1765265991653,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "Daf6P0TvFSPl",
    "papermill": {
     "duration": 0.068813,
     "end_time": "2025-12-12T10:27:38.859468",
     "exception": false,
     "start_time": "2025-12-12T10:27:38.790655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37617ba",
   "metadata": {
    "id": "rEM-I6SeXH0h",
    "papermill": {
     "duration": 0.007507,
     "end_time": "2025-12-12T10:27:38.874614",
     "exception": false,
     "start_time": "2025-12-12T10:27:38.867107",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "595f9199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:38.890795Z",
     "iopub.status.busy": "2025-12-12T10:27:38.890228Z",
     "iopub.status.idle": "2025-12-12T10:27:38.893409Z",
     "shell.execute_reply": "2025-12-12T10:27:38.892833Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1765265991666,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "SlpYuvDC4Ib9",
    "papermill": {
     "duration": 0.012481,
     "end_time": "2025-12-12T10:27:38.894518",
     "exception": false,
     "start_time": "2025-12-12T10:27:38.882037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/sigsep/sigsep-mus-db - примеры работы с musdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d9996",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1765265991670,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "9RE3Rfc3HpHZ",
    "papermill": {
     "duration": 0.00759,
     "end_time": "2025-12-12T10:27:38.909523",
     "exception": false,
     "start_time": "2025-12-12T10:27:38.901933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bf871ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:38.925905Z",
     "iopub.status.busy": "2025-12-12T10:27:38.925695Z",
     "iopub.status.idle": "2025-12-12T10:27:39.036311Z",
     "shell.execute_reply": "2025-12-12T10:27:39.035679Z"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1765265991702,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "H8zmd2hNHGWq",
    "papermill": {
     "duration": 0.12056,
     "end_time": "2025-12-12T10:27:39.037515",
     "exception": false,
     "start_time": "2025-12-12T10:27:38.916955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MusDBDataset(Dataset):\n",
    "  def __init__(self, mus_dataset\n",
    "               , current_sample_rate\n",
    "               , target_sample_rate\n",
    "               , num_input_seconds\n",
    "               , num_output_seconds\n",
    "               , one_bit_seconds\n",
    "               , device = device):\n",
    "    super().__init__()\n",
    "\n",
    "    self.mus_dataset = mus_dataset\n",
    "    self.current_sample_rate = current_sample_rate\n",
    "    self.target_sample_rate = target_sample_rate\n",
    "    self.num_input_seconds = num_input_seconds\n",
    "    self.num_output_seconds = num_output_seconds\n",
    "    self.one_bit_seconds = one_bit_seconds\n",
    "    self.num_bits_in_second = 1 / self.one_bit_seconds # избегаем ошибку округления\n",
    "    self.device = device\n",
    "\n",
    "    self.resampler = T.Resample(self.current_sample_rate, self.target_sample_rate)\n",
    "\n",
    "    self.durations = list(map(lambda track: track.duration, self.mus_dataset))\n",
    "    self.num_possible_samples_from_track = list(\n",
    "        map(\n",
    "            lambda duration: int((duration - self.num_input_seconds \\\n",
    "                              - self.num_output_seconds) \\\n",
    "            * self.num_bits_in_second) + 1,\n",
    "            self.durations)\n",
    "        )\n",
    "    self.start_seconds = []\n",
    "    for idx, num_samples in enumerate(self.num_possible_samples_from_track):\n",
    "      self.start_seconds.extend([(\n",
    "          idx, i/self.num_bits_in_second\n",
    "          ) for i in range(int(num_samples))])\n",
    "\n",
    "    self.cached_tracks = {}\n",
    "    self.cached_parts = {}\n",
    "\n",
    "    self.expected_shape_X = int(self.num_input_seconds*self.target_sample_rate)\n",
    "    self.expected_shape_y = int(self.num_output_seconds*self.target_sample_rate)\n",
    "\n",
    "\n",
    "  def _change_sample_rate(self, array, current_sample_rate, target_sample_rate):\n",
    "    array = torch.tensor(array, dtype=torch.float32)\n",
    "\n",
    "    if current_sample_rate!=target_sample_rate:\n",
    "      array = self.resampler(array)\n",
    "\n",
    "    return array.to(device)\n",
    "\n",
    "  def __len__(self):\n",
    "    return sum(self.num_possible_samples_from_track)\n",
    "\n",
    "  def _pad(self, item, expectation):\n",
    "    return torch.nn.functional.pad(item, (0, expectation-item.shape[0]))\n",
    "\n",
    "  def _prepare_track(self, track_num, start):\n",
    "\n",
    "    if self.cached_tracks.get(track_num, 'no') == 'no':\n",
    "\n",
    "      track = self.mus_dataset[track_num]\n",
    "\n",
    "\n",
    "\n",
    "      vocals = self._change_sample_rate(track.targets['vocals'].audio.mean(axis=-1)\n",
    "                                          , self.current_sample_rate\n",
    "                                          , self.target_sample_rate)\n",
    "      drums = self._change_sample_rate(track.targets['drums'].audio.mean(axis=-1)\n",
    "                                      , self.current_sample_rate\n",
    "                                      , self.target_sample_rate)\n",
    "      bass = self._change_sample_rate(track.targets['bass'].audio.mean(axis=-1)\n",
    "                                      , self.current_sample_rate\n",
    "                                      , self.target_sample_rate)\n",
    "      other = self._change_sample_rate(track.targets['other'].audio.mean(axis=-1)\n",
    "                                      , self.current_sample_rate\n",
    "                                      , self.target_sample_rate)\n",
    "      all = self._change_sample_rate(track.audio.mean(axis=-1)\n",
    "                                      , self.current_sample_rate\n",
    "                                      , self.target_sample_rate)\n",
    "\n",
    "      self.cached_tracks[track_num] = {'vocals':vocals\n",
    "                                       , 'drums':drums\n",
    "                                       , 'bass':bass\n",
    "                                       , 'other':other\n",
    "                                       , 'all':all}\n",
    "\n",
    "    track = self.cached_tracks[track_num]\n",
    "    vocals = track['vocals']\n",
    "    drums = track['drums']\n",
    "    bass = track['bass']\n",
    "    other = track['other']\n",
    "    all = track['all']\n",
    "\n",
    "    end_X = start + self.num_input_seconds\n",
    "    end_y = end_X + self.num_output_seconds\n",
    "\n",
    "    start_X = start * self.target_sample_rate\n",
    "    start_X = int(start_X)\n",
    "\n",
    "    end_X *= self.target_sample_rate\n",
    "    end_X = int(end_X)\n",
    "\n",
    "    end_y *= self.target_sample_rate\n",
    "    end_y = int(end_y)\n",
    "\n",
    "    vocals_X = self._pad(vocals[start_X:end_X], self.expected_shape_X)\n",
    "    vocals_y = self._pad(vocals[end_X:end_y], self.expected_shape_y)\n",
    "\n",
    "\n",
    "\n",
    "    drums_X = self._pad(drums[start_X:end_X], self.expected_shape_X)\n",
    "    drums_y = self._pad(drums[end_X:end_y], self.expected_shape_y)\n",
    "\n",
    "\n",
    "\n",
    "    bass_X = self._pad(bass[start_X:end_X], self.expected_shape_X)\n",
    "    bass_y = self._pad(bass[end_X:end_y], self.expected_shape_y)\n",
    "\n",
    "\n",
    "\n",
    "    other_X = self._pad(other[start_X:end_X], self.expected_shape_X)\n",
    "    other_y = self._pad(other[end_X:end_y], self.expected_shape_y)\n",
    "\n",
    "\n",
    "\n",
    "    all_X = self._pad(other[start_X:end_X], self.expected_shape_X)\n",
    "    all_y = self._pad(other[end_X:end_y], self.expected_shape_y)\n",
    "\n",
    "\n",
    "\n",
    "    return {'vocals':(vocals_X[:self.expected_shape_X]\n",
    "                      , vocals_y[:self.expected_shape_y]),\n",
    "                            'drums':(drums_X[:self.expected_shape_X]\n",
    "                                     , drums_y)[:self.expected_shape_y],\n",
    "                            'bass':(bass_X[:self.expected_shape_X]\n",
    "                                    , bass_y[:self.expected_shape_y]),\n",
    "                            'other':(other[:self.expected_shape_X]\n",
    "                                     , other_y)[:self.expected_shape_y],\n",
    "                            'all':(all_X[:self.expected_shape_X]\n",
    "                                   , all_y[:self.expected_shape_y])}\n",
    "\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    # return self.final_list[idx]\n",
    "    # if self.cached_parts.get(idx, 'no') == 'no':\n",
    "    track_num, start_timestep = self.start_seconds[idx]\n",
    "    preprocessed_data = self._prepare_track(track_num, start_timestep)\n",
    "    # self.cached_parts[idx] = preprocessed_data\n",
    "\n",
    "    return preprocessed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b4a0a2",
   "metadata": {
    "id": "pYCwO93CIHP3",
    "papermill": {
     "duration": 0.007485,
     "end_time": "2025-12-12T10:27:39.052894",
     "exception": false,
     "start_time": "2025-12-12T10:27:39.045409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Мок модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f68ee8fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:39.069180Z",
     "iopub.status.busy": "2025-12-12T10:27:39.068674Z",
     "iopub.status.idle": "2025-12-12T10:27:39.072621Z",
     "shell.execute_reply": "2025-12-12T10:27:39.072091Z"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1765265991748,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "zkW2gfdEFWxX",
    "papermill": {
     "duration": 0.013126,
     "end_time": "2025-12-12T10:27:39.073695",
     "exception": false,
     "start_time": "2025-12-12T10:27:39.060569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MockNet(nn.Module):\n",
    "  def __init__(self, input_size, output_size):\n",
    "    super().__init__()\n",
    "    self.input_size = input_size\n",
    "    self.output_size = output_size\n",
    "    self.linear = nn.Linear(self.input_size, self.output_size)\n",
    "    self.activ = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, X):\n",
    "    return self.activ(self.linear(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888b0a86",
   "metadata": {
    "id": "ccayZAVhFfrP",
    "papermill": {
     "duration": 0.007362,
     "end_time": "2025-12-12T10:27:39.088456",
     "exception": false,
     "start_time": "2025-12-12T10:27:39.081094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Конфиг\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bdb2a03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:39.103977Z",
     "iopub.status.busy": "2025-12-12T10:27:39.103781Z",
     "iopub.status.idle": "2025-12-12T10:27:39.107529Z",
     "shell.execute_reply": "2025-12-12T10:27:39.106977Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1765265991750,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "85N-sClUJQ_h",
    "papermill": {
     "duration": 0.012734,
     "end_time": "2025-12-12T10:27:39.108574",
     "exception": false,
     "start_time": "2025-12-12T10:27:39.095840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {'current_sample_rate':22050,\n",
    "'target_sample_rate': 22050,\n",
    "'num_input_seconds': 5,\n",
    "'num_output_seconds': 0.5,\n",
    "'one_bit_seconds': 0.2,\n",
    "'n_fft': 1024,\n",
    "'batch_size': 8,\n",
    "'learning_rate': 5e-5,\n",
    "          'mel_bins': 128,\n",
    "    'dropout_rate': 0.2,\n",
    "    'use_bidirectional': False  # Recommended True for audio sequences\n",
    "          , 'test_size': 0.2\n",
    "          , 'num_epochs': 10\n",
    "          , 'spectral_backward': False\n",
    "          , 'use_7s': True\n",
    "          , 'target_log': True\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e326a89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:39.124539Z",
     "iopub.status.busy": "2025-12-12T10:27:39.124102Z",
     "iopub.status.idle": "2025-12-12T10:27:39.127718Z",
     "shell.execute_reply": "2025-12-12T10:27:39.127222Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1765265991754,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "XYCld7up5ji9",
    "papermill": {
     "duration": 0.012555,
     "end_time": "2025-12-12T10:27:39.128667",
     "exception": false,
     "start_time": "2025-12-12T10:27:39.116112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config['hop_length']= config['n_fft']//2\n",
    "config['sequence_length_input'] = int(1 + (config['num_input_seconds']*config['target_sample_rate'] - config['n_fft']) // config['hop_length'] + 2)\n",
    "config['sequence_length_output'] = int(1 + (config['num_output_seconds']*config['target_sample_rate'] - config['n_fft']) // config['hop_length'] + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb1a4cb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:39.144427Z",
     "iopub.status.busy": "2025-12-12T10:27:39.144228Z",
     "iopub.status.idle": "2025-12-12T10:27:39.147016Z",
     "shell.execute_reply": "2025-12-12T10:27:39.146530Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1765265991763,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "mKaVnToTOcWb",
    "papermill": {
     "duration": 0.011882,
     "end_time": "2025-12-12T10:27:39.148102",
     "exception": false,
     "start_time": "2025-12-12T10:27:39.136220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53203fff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:39.163822Z",
     "iopub.status.busy": "2025-12-12T10:27:39.163630Z",
     "iopub.status.idle": "2025-12-12T10:27:39.168126Z",
     "shell.execute_reply": "2025-12-12T10:27:39.167487Z"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1765265991800,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "EIpR_oAhOjOY",
    "papermill": {
     "duration": 0.013515,
     "end_time": "2025-12-12T10:27:39.169146",
     "exception": false,
     "start_time": "2025-12-12T10:27:39.155631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Stem:\n",
    "    audio: np.ndarray = None\n",
    "\n",
    "@dataclass\n",
    "class Track:\n",
    "    audio: np.ndarray = None\n",
    "    targets: dict = field(default_factory=lambda: {\n",
    "'vocals': Stem(),\n",
    "'drums': Stem(),\n",
    "'bass': Stem(),\n",
    "'other': Stem()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd6a0004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:39.185001Z",
     "iopub.status.busy": "2025-12-12T10:27:39.184512Z",
     "iopub.status.idle": "2025-12-12T10:27:39.187437Z",
     "shell.execute_reply": "2025-12-12T10:27:39.186874Z"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1765265991815,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "oxnM3GyZ1Pi1",
    "papermill": {
     "duration": 0.011872,
     "end_time": "2025-12-12T10:27:39.188480",
     "exception": false,
     "start_time": "2025-12-12T10:27:39.176608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddc53c80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:39.204194Z",
     "iopub.status.busy": "2025-12-12T10:27:39.203976Z",
     "iopub.status.idle": "2025-12-12T10:27:39.206701Z",
     "shell.execute_reply": "2025-12-12T10:27:39.206214Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1765265991816,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "8VVBCCmMIcmy",
    "papermill": {
     "duration": 0.011682,
     "end_time": "2025-12-12T10:27:39.207707",
     "exception": false,
     "start_time": "2025-12-12T10:27:39.196025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8b6ebd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:39.223686Z",
     "iopub.status.busy": "2025-12-12T10:27:39.223494Z",
     "iopub.status.idle": "2025-12-12T10:27:57.047096Z",
     "shell.execute_reply": "2025-12-12T10:27:57.046460Z"
    },
    "executionInfo": {
     "elapsed": 28400,
     "status": "ok",
     "timestamp": 1765266020219,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "7ZkEvhkQXkpD",
    "outputId": "7ca78307-20a3-4d1f-d688-e846cab9a7a0",
    "papermill": {
     "duration": 17.833318,
     "end_time": "2025-12-12T10:27:57.048533",
     "exception": false,
     "start_time": "2025-12-12T10:27:39.215215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading MUSDB 7s Sample Dataset to /root/MUSDB18/MUSDB18-7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140M/140M [00:01<00:00, 118MB/s]\n"
     ]
    }
   ],
   "source": [
    "if config['use_7s']:\n",
    "  mus = musdb.DB(download=True, sample_rate=config['target_sample_rate'])\n",
    "\n",
    "else:\n",
    "  !gdown 1_6ivqpFCdflkd7JMyyx6_PMT1IaThEPu\n",
    "  !mkdir ./musdb18\n",
    "  !tar -xvzf ./musdb18.tar.gz -C ./\n",
    "  !mkdir ./musdb18/train_extracted\n",
    "  !mkdir ./musdb18/test_extracted\n",
    "  stems_map = {0: 'mixture', 1: 'drums', 2: 'bass', 3: 'other', 4: 'vocals'}\n",
    "  mus = []\n",
    "  train_folder = os.listdir('./musdb18/train')\n",
    "  test_folder = os.listdir('./musdb18/test')\n",
    "  for filename in tqdm(train_folder):\n",
    "    try:\n",
    "      if not filename.startswith('_'):\n",
    "        track = Track()\n",
    "\n",
    "        for i in range(5):\n",
    "          audio, _ = stempeg.read_stems('./musdb18/train/'+filename,\n",
    "                                        stem_id=i,\n",
    "                      sample_rate=config['target_sample_rate'],\n",
    "                      ffmpeg_format=\"s16le\"\n",
    "                  )\n",
    "\n",
    "          audio = audio.astype('float16')\n",
    "          if audio.shape[-1] == 2:\n",
    "            audio = audio.mean(-1).reshape(-1, 1)\n",
    "          if i == 0:\n",
    "            track.audio = audio\n",
    "          else:\n",
    "            track.targets[stems_map[i]].audio = audio\n",
    "          track.duration = audio.shape[0] / config['target_sample_rate']\n",
    "\n",
    "        vocals = track.targets['vocals'].audio.mean(axis=-1)\n",
    "        drums = track.targets['drums'].audio.mean(axis=-1)\n",
    "        bass = track.targets['bass'].audio.mean(axis=-1)\n",
    "        other = track.targets['other'].audio.mean(axis=-1)\n",
    "        all = track.audio.mean(axis=-1)\n",
    "        with open('./musdb18/train_extracted/'+filename+'.'+str(round(track.duration, 2))+'.pkl', 'wb') as f:\n",
    "          joblib.dump({'vocals':vocals\n",
    "                                        , 'drums':drums\n",
    "                                        , 'bass':bass\n",
    "                                        , 'other':other\n",
    "                                        , 'all':all}, f)\n",
    "\n",
    "    except Exception as E:\n",
    "      # print(E)\n",
    "      continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  mus_test = []\n",
    "  for filename in tqdm(test_folder):\n",
    "    try:\n",
    "      if not filename.startswith('._'):\n",
    "        track = Track()\n",
    "\n",
    "        for i in range(5):\n",
    "          audio, _ = stempeg.read_stems('./musdb18/test/'+filename,\n",
    "                                        stem_id=i,\n",
    "                      sample_rate=config['target_sample_rate'],\n",
    "                      ffmpeg_format=\"s16le\"\n",
    "                  )\n",
    "\n",
    "          audio = audio.astype('float16')\n",
    "          if audio.shape[-1] == 2:\n",
    "            audio = audio.mean(-1)\n",
    "          if i == 0:\n",
    "            track.audio = audio\n",
    "          else:\n",
    "            track.targets[stems_map[i]].audio = audio\n",
    "          track.duration = audio.shape[0] / config['target_sample_rate']\n",
    "        vocals = track.targets['vocals'].audio.mean(axis=-1)\n",
    "        drums = track.targets['drums'].audio.mean(axis=-1)\n",
    "        bass = track.targets['bass'].audio.mean(axis=-1)\n",
    "        other = track.targets['other'].audio.mean(axis=-1)\n",
    "        all = track.audio.mean(axis=-1)\n",
    "        with open('./musdb18/test_extracted/'+filename+'.'+str(round(track.duration, 2))+'.pkl', 'wb') as f:\n",
    "          joblib.dump({'vocals':vocals\n",
    "                                        , 'drums':drums\n",
    "                                        , 'bass':bass\n",
    "                                        , 'other':other\n",
    "                                        , 'all':all}, f)\n",
    "    except:\n",
    "      continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f4067b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.066148Z",
     "iopub.status.busy": "2025-12-12T10:27:57.065923Z",
     "iopub.status.idle": "2025-12-12T10:27:57.069460Z",
     "shell.execute_reply": "2025-12-12T10:27:57.068957Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1765266020223,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "Etw_ONcPfykJ",
    "papermill": {
     "duration": 0.013437,
     "end_time": "2025-12-12T10:27:57.070699",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.057262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for filename in tqdm(test_folder):\n",
    "\n",
    "#   if not filename.startswith('._'):\n",
    "#     track = Track()\n",
    "\n",
    "#     for i in range(5):\n",
    "#       audio, _ = stempeg.read_stems('./musdb18/test/'+filename,\n",
    "#                                     stem_id=i,\n",
    "#                   sample_rate=config['target_sample_rate'],\n",
    "#                   ffmpeg_format=\"s16le\"\n",
    "#               )\n",
    "\n",
    "#       audio = audio.astype('float16')\n",
    "#       if audio.shape[-1] == 2:\n",
    "#         audio = audio.mean(-1)\n",
    "#       if i == 0:\n",
    "#         track.audio = audio\n",
    "#       else:\n",
    "#         track.targets[stems_map[i]].audio = audio\n",
    "#       track.duration = audio.shape[0] / config['target_sample_rate']\n",
    "#     vocals = track.targets['vocals'].audio.mean(axis=-1)\n",
    "#     drums = track.targets['drums'].audio.mean(axis=-1)\n",
    "#     bass = track.targets['bass'].audio.mean(axis=-1)\n",
    "#     other = track.targets['other'].audio.mean(axis=-1)\n",
    "#     all = track.audio.mean(axis=-1)\n",
    "#     with open('./musdb18/test_extracted/'+filename+'.'+str(round(track.duration, 2))+'.pkl', 'wb') as f:\n",
    "#       joblib.dump({'vocals':vocals\n",
    "#                                     , 'drums':drums\n",
    "#                                     , 'bass':bass\n",
    "#                                     , 'other':other\n",
    "#                                     , 'all':all}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60803a13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.088265Z",
     "iopub.status.busy": "2025-12-12T10:27:57.087550Z",
     "iopub.status.idle": "2025-12-12T10:27:57.090824Z",
     "shell.execute_reply": "2025-12-12T10:27:57.090320Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1765266020238,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "ieMTNmOTOPJj",
    "papermill": {
     "duration": 0.012757,
     "end_time": "2025-12-12T10:27:57.091765",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.079008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30a7e7ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.108987Z",
     "iopub.status.busy": "2025-12-12T10:27:57.108780Z",
     "iopub.status.idle": "2025-12-12T10:27:57.120442Z",
     "shell.execute_reply": "2025-12-12T10:27:57.119846Z"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1765266020251,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "Ou1aqOElKGJR",
    "papermill": {
     "duration": 0.021641,
     "end_time": "2025-12-12T10:27:57.121422",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.099781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MusDBDatasetCached(Dataset):\n",
    "  def __init__(self, mus_dataset_path\n",
    "               , current_sample_rate\n",
    "               , target_sample_rate\n",
    "               , num_input_seconds\n",
    "               , num_output_seconds\n",
    "               , one_bit_seconds\n",
    "               , device = device):\n",
    "    super().__init__()\n",
    "\n",
    "    self.mus_dataset_path = mus_dataset_path\n",
    "    self.mus_dataset_filenames = os.listdir(mus_dataset_path)\n",
    "    self.current_sample_rate = current_sample_rate\n",
    "    self.target_sample_rate = target_sample_rate\n",
    "    self.num_input_seconds = num_input_seconds\n",
    "    self.num_output_seconds = num_output_seconds\n",
    "    self.one_bit_seconds = one_bit_seconds\n",
    "    self.num_bits_in_second = 1 / self.one_bit_seconds # избегаем ошибку округления\n",
    "    self.device = device\n",
    "\n",
    "    self.durations = list(map(lambda filename: float(filename.split('.')[-3]+'.'+filename.split('.')[-2]), self.mus_dataset_filenames))\n",
    "    self.num_possible_samples_from_track = list(\n",
    "        map(\n",
    "            lambda duration: int((duration - self.num_input_seconds \\\n",
    "                              - self.num_output_seconds) \\\n",
    "            * self.num_bits_in_second) + 1,\n",
    "            self.durations)\n",
    "        )\n",
    "    self.start_seconds = []\n",
    "    for idx, num_samples in enumerate(self.num_possible_samples_from_track):\n",
    "      self.start_seconds.extend([(\n",
    "          idx, i/self.num_bits_in_second\n",
    "          ) for i in range(int(num_samples))])\n",
    "\n",
    "    self.cached_parts = {}\n",
    "\n",
    "    self.expected_shape_X = int(self.num_input_seconds*self.target_sample_rate)\n",
    "    self.expected_shape_y = int(self.num_output_seconds*self.target_sample_rate)\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return sum(self.num_possible_samples_from_track)\n",
    "\n",
    "  def _pad(self, item, expectation):\n",
    "    return torch.nn.functional.pad(item, (0, expectation-item.shape[0]))\n",
    "\n",
    "  def _prepare_track(self, track_num, start):\n",
    "\n",
    "    with open(os.path.join(self.mus_dataset_path\n",
    "                           , self.mus_dataset_filenames[track_num]), 'rb') as f:\n",
    "      track = joblib.load(f)\n",
    "    vocals = torch.tensor(track['vocals'], device=self.device)\n",
    "    drums = torch.tensor(track['drums'], device=self.device)\n",
    "    bass = torch.tensor(track['bass'], device=self.device)\n",
    "    other = torch.tensor(track['other'], device=self.device)\n",
    "    all = torch.tensor(track['all'], device=self.device)\n",
    "\n",
    "    end_X = start + self.num_input_seconds\n",
    "    end_y = end_X + self.num_output_seconds\n",
    "\n",
    "    start_X = start * self.target_sample_rate\n",
    "    start_X = int(start_X)\n",
    "\n",
    "    end_X *= self.target_sample_rate\n",
    "    end_X = int(end_X)\n",
    "\n",
    "    end_y *= self.target_sample_rate\n",
    "    end_y = int(end_y)\n",
    "\n",
    "    vocals_X = self._pad(vocals[start_X:end_X], self.expected_shape_X)\n",
    "    vocals_y = self._pad(vocals[end_X:end_y], self.expected_shape_y)\n",
    "\n",
    "\n",
    "    drums_X = self._pad(drums[start_X:end_X], self.expected_shape_X)\n",
    "    drums_y = self._pad(drums[end_X:end_y], self.expected_shape_y)\n",
    "\n",
    "\n",
    "    bass_X = self._pad(bass[start_X:end_X], self.expected_shape_X)\n",
    "    bass_y = self._pad(bass[end_X:end_y], self.expected_shape_y)\n",
    "\n",
    "\n",
    "\n",
    "    other_X = self._pad(other[start_X:end_X], self.expected_shape_X)\n",
    "    other_y = self._pad(other[end_X:end_y], self.expected_shape_y)\n",
    "\n",
    "\n",
    "\n",
    "    all_X = self._pad(other[start_X:end_X], self.expected_shape_X)\n",
    "    all_y = self._pad(other[end_X:end_y], self.expected_shape_y)\n",
    "\n",
    "\n",
    "\n",
    "    return {'vocals':(vocals_X[:self.expected_shape_X]\n",
    "                      , vocals_y[:self.expected_shape_y]),\n",
    "                            'drums':(drums_X[:self.expected_shape_X]\n",
    "                                     , drums_y)[:self.expected_shape_y],\n",
    "                            'bass':(bass_X[:self.expected_shape_X]\n",
    "                                    , bass_y[:self.expected_shape_y]),\n",
    "                            'other':(other[:self.expected_shape_X]\n",
    "                                     , other_y)[:self.expected_shape_y],\n",
    "                            'all':(all_X[:self.expected_shape_X]\n",
    "                                   , all_y[:self.expected_shape_y])}\n",
    "\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    # return self.final_list[idx]\n",
    "    # if self.cached_parts.get(idx, 'no') == 'no':\n",
    "    track_num, start_timestep = self.start_seconds[idx]\n",
    "    preprocessed_data = self._prepare_track(track_num, start_timestep)\n",
    "    # self.cached_parts[idx] = preprocessed_data\n",
    "\n",
    "    return preprocessed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "453d8597",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.138491Z",
     "iopub.status.busy": "2025-12-12T10:27:57.138288Z",
     "iopub.status.idle": "2025-12-12T10:27:57.144534Z",
     "shell.execute_reply": "2025-12-12T10:27:57.143985Z"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1765266020252,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "OmhMBbqiYGzt",
    "papermill": {
     "duration": 0.016009,
     "end_time": "2025-12-12T10:27:57.145494",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.129485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['use_7s']:\n",
    "  mus_train, mus_test = train_test_split(mus, test_size=config['test_size'], random_state=42)\n",
    "\n",
    "  musdb_train = MusDBDataset(mus_train\n",
    "                      , current_sample_rate=config['target_sample_rate']\n",
    "                      , target_sample_rate=config['target_sample_rate']\n",
    "                      , num_input_seconds=config['num_input_seconds']\n",
    "                      , num_output_seconds=config['num_output_seconds']\n",
    "                      , one_bit_seconds=config['one_bit_seconds']\n",
    "                      , device=device)\n",
    "  musdb_test = MusDBDataset(mus_test\n",
    "                      , current_sample_rate=config['target_sample_rate']\n",
    "                      , target_sample_rate=config['target_sample_rate']\n",
    "                      , num_input_seconds=config['num_input_seconds']\n",
    "                      , num_output_seconds=config['num_output_seconds']\n",
    "                      , one_bit_seconds=config['one_bit_seconds']\n",
    "                      , device=device)\n",
    "\n",
    "else:\n",
    "\n",
    "  musdb_train = MusDBDatasetCached('./musdb18/train_extracted'\n",
    "  , current_sample_rate=config['target_sample_rate']\n",
    "                      , target_sample_rate=config['target_sample_rate']\n",
    "                      , num_input_seconds=config['num_input_seconds']\n",
    "                      , num_output_seconds=config['num_output_seconds']\n",
    "                      , one_bit_seconds=config['one_bit_seconds']\n",
    "                      , device=device)\n",
    "  musdb_test = MusDBDatasetCached('./musdb18/test_extracted'\n",
    "  , current_sample_rate=config['target_sample_rate']\n",
    "                      , target_sample_rate=config['target_sample_rate']\n",
    "                      , num_input_seconds=config['num_input_seconds']\n",
    "                      , num_output_seconds=config['num_output_seconds']\n",
    "                      , one_bit_seconds=config['one_bit_seconds']\n",
    "                      , device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35360b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.162050Z",
     "iopub.status.busy": "2025-12-12T10:27:57.161843Z",
     "iopub.status.idle": "2025-12-12T10:27:57.165129Z",
     "shell.execute_reply": "2025-12-12T10:27:57.164627Z"
    },
    "executionInfo": {
     "elapsed": 138,
     "status": "ok",
     "timestamp": 1765266020390,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "fxP8pUt2JAme",
    "papermill": {
     "duration": 0.012839,
     "end_time": "2025-12-12T10:27:57.166228",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.153389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mus_dl_train = DataLoader(musdb_train, batch_size=config['batch_size'], shuffle=True)\n",
    "mus_dl_test = DataLoader(musdb_test, batch_size=config['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1881435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.183325Z",
     "iopub.status.busy": "2025-12-12T10:27:57.182720Z",
     "iopub.status.idle": "2025-12-12T10:27:57.287323Z",
     "shell.execute_reply": "2025-12-12T10:27:57.286713Z"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1765266020418,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "0N2XAsng8uCN",
    "outputId": "bac20210-8dbd-4518-892f-8d995f2e642f",
    "papermill": {
     "duration": 0.114515,
     "end_time": "2025-12-12T10:27:57.288643",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.174128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del mus\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b9415b",
   "metadata": {
    "id": "_74444xXQ7Fa",
    "papermill": {
     "duration": 0.00921,
     "end_time": "2025-12-12T10:27:57.306614",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.297404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Метрики\n",
    "\n",
    "Одной хорошей нет, нужен набор.\n",
    "\n",
    "- Типы метрик по объекту оценки: Fidelity (качество аудиодорожки), Musicality (музыкальные характеристики аудиодорожки).\n",
    "- Типы метрик по необходимости аудио: для мелспектрограмм, для аудио\n",
    "- Типы метрик по оценке распределений: достаточно одного трека, необходим набор треков\n",
    "- Как оценивать: автоматически, с использованием человеческой оценки\n",
    "\n",
    "Ниже описываются только автоматические метрики для Fidelity.\n",
    "\n",
    "Fidelity: \\\n",
    "1/ Frechet Audio Distance - для аудио, для распределения. Считается на эмбеддингах аудио (эвклидово расстояние центроидов эмбеддингов + след матрицы ковариаций). Есть нюансы с тем, какую модель эмбеддингов использовать: самый простой вариант - VGGish, наибольшую корреляцию с человеческой оценкой показывает на CLAP (https://arxiv.org/pdf/2506.19085). Есть расширение FAD-infinity для коррекции на размер батча. \\\n",
    "2/ CosineSim для эмбеддингов - аудио, отдельные треки/дорожки. Берём текстовые эмбеддинги CLAP для сгенерированного и эталонного аудио, считаем расстояние.\\\n",
    "3/ Reconstruction Loss - мелки/аудио, треки/дорожки. Прямолинейно. Считаем MSE на значения сгенерированной и эталонной спектрограмм. \\\n",
    "4/ Vendi Score (https://openreview.net/pdf?id=g97OHbQyk1) - аудио, распределение треков. Энтропия собственных значений матрицы схожести  эмбеддингов сгенерированной музыки. Метрика разнообразия. \\\n",
    "Musicality :\\\n",
    "Для мелок используются спектральные статистики. Центроид - оценка, какие частоты преобладают (высокие или низкие). Спектральная ширина - ширина спектра вокруг центроида (чем шире, тем сложнее тембр). Спектральная плоскость - Показывает, насколько спектр похож на шум (плоский) или на тон (пикообразный). Спектральная энтропия - насколько равномерно распределен сигнал по частотам (шум или не шум).\n",
    "\n",
    "\n",
    "Также есть ритмические и тембральные характеристики, но они считаются на аудио (не на мелспектрограммах) и спектральные статистики их могут частично компенсировать.\n",
    "\n",
    "\n",
    "Подходы с обучением дополнительных моделей:\n",
    "- по мелспектрограммам предсказывать метрики, которые считаются только на аудио или на эмбеддингах, и использовать как дополнительные таргеты при обучении.\n",
    "- Wasserstein GAN (Adversarial Loss). Для стабильного обучения лучше дополнительно сравнивать фичи из спектрограмм.\n",
    "- RLHF на человеческой разметке.\n",
    "\n",
    "Для бейзлайна предлагаю использовать спектральные статистики + Reconstruction Loss (см ниже), чтобы не обучать дополнительные модели.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72010c7c",
   "metadata": {
    "id": "2Jg9dEWwGMgB",
    "papermill": {
     "duration": 0.008157,
     "end_time": "2025-12-12T10:27:57.322809",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.314652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Функции для расчёта лоссов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb651b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.340336Z",
     "iopub.status.busy": "2025-12-12T10:27:57.339743Z",
     "iopub.status.idle": "2025-12-12T10:27:57.344058Z",
     "shell.execute_reply": "2025-12-12T10:27:57.343548Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1765266020420,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "5u94Sb81jEdr",
    "papermill": {
     "duration": 0.014337,
     "end_time": "2025-12-12T10:27:57.345166",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.330829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def spectral_centroid_fn(mel_spec):\n",
    "  \"\"\"Спектральный центроид\"\"\"\n",
    "  mel_spec = mel_spec.unsqueeze(1)\n",
    "  freqs = torch.linspace(0, 1, mel_spec.size(2), device=mel_spec.device)\n",
    "  freqs = freqs.view(1, 1, -1, 1)\n",
    "  weighted = mel_spec * freqs\n",
    "  spectral_centroid = torch.sum(weighted, dim=2) / (torch.sum(mel_spec, dim=2) + 1e-8)\n",
    "  return spectral_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7d99ee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.362675Z",
     "iopub.status.busy": "2025-12-12T10:27:57.362471Z",
     "iopub.status.idle": "2025-12-12T10:27:57.366894Z",
     "shell.execute_reply": "2025-12-12T10:27:57.366404Z"
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1765266020519,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "YCRuK3PARxMf",
    "papermill": {
     "duration": 0.014564,
     "end_time": "2025-12-12T10:27:57.367984",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.353420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def spectral_bandwidth_fn(mel_spec):\n",
    "  \"\"\"\n",
    "  Спектральная ширина - разброс частот\n",
    "  \"\"\"\n",
    "  centroid = spectral_centroid_fn(mel_spec).unsqueeze(1)  # [batch, 1, time]\n",
    "\n",
    "  mel_frequencies = torch.linspace(0, 1, config['mel_bins'], device=mel_spec.device)\\\n",
    "  .unsqueeze(0).unsqueeze(-1)\n",
    "\n",
    "  # Нормализуем\n",
    "  mel_spec_normalized = mel_spec / (torch.sum(mel_spec, dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "  # Вычисляем дисперсию вокруг центроида\n",
    "  freq_diff = (mel_frequencies - centroid) ** 2\n",
    "  bandwidth = torch.sum(freq_diff * mel_spec_normalized, dim=1)  # [batch, time]\n",
    "\n",
    "  return torch.sqrt(bandwidth + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1bab1b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.385738Z",
     "iopub.status.busy": "2025-12-12T10:27:57.385536Z",
     "iopub.status.idle": "2025-12-12T10:27:57.389420Z",
     "shell.execute_reply": "2025-12-12T10:27:57.388838Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1765266020533,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "zPWyrTtdSWlk",
    "papermill": {
     "duration": 0.013838,
     "end_time": "2025-12-12T10:27:57.390448",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.376610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def spectral_flatness_fn(mel_spec):\n",
    "  \"\"\"\n",
    "  Спектральная плоскость - тональность vs шумность\n",
    "  \"\"\"\n",
    "  # Геометрическое среднее\n",
    "  geometric_mean = torch.exp(torch.mean(torch.log(mel_spec + 1e-8), dim=1))\n",
    "\n",
    "  # Арифметическое среднее\n",
    "  arithmetic_mean = torch.mean(mel_spec, dim=1)\n",
    "\n",
    "  # Спектральная плоскость\n",
    "  flatness = geometric_mean / (arithmetic_mean + 1e-8)\n",
    "\n",
    "  return flatness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56dc7ebe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.407654Z",
     "iopub.status.busy": "2025-12-12T10:27:57.407460Z",
     "iopub.status.idle": "2025-12-12T10:27:57.411267Z",
     "shell.execute_reply": "2025-12-12T10:27:57.410736Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1765266020535,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "y5gJHuclShnd",
    "papermill": {
     "duration": 0.013662,
     "end_time": "2025-12-12T10:27:57.412306",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.398644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def spectral_entropy_fn(mel_spec):\n",
    "  \"\"\"\n",
    "  Спектральная энтропия - сложность текстуры\n",
    "  \"\"\"\n",
    "  # Нормализуем каждый временной кадр\n",
    "  mel_normalized = mel_spec / (torch.sum(mel_spec, dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "  # Вычисляем энтропию\n",
    "  entropy = -torch.sum(mel_normalized * torch.log(mel_normalized + 1e-8), dim=1)\n",
    "\n",
    "  # Нормализуем энтропию к [0, 1]\n",
    "  max_entropy = torch.log(torch.tensor(mel_spec.size(1), device=mel_spec.device))\n",
    "  normalized_entropy = entropy / max_entropy\n",
    "\n",
    "  return normalized_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "069549a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.429768Z",
     "iopub.status.busy": "2025-12-12T10:27:57.429577Z",
     "iopub.status.idle": "2025-12-12T10:27:57.432556Z",
     "shell.execute_reply": "2025-12-12T10:27:57.432047Z"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1765266020547,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "_Tr1gop0ENw6",
    "papermill": {
     "duration": 0.013212,
     "end_time": "2025-12-12T10:27:57.433548",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.420336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(tensor):\n",
    "  return tensor / tensor.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4efb28f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.450698Z",
     "iopub.status.busy": "2025-12-12T10:27:57.450511Z",
     "iopub.status.idle": "2025-12-12T10:27:57.453874Z",
     "shell.execute_reply": "2025-12-12T10:27:57.453378Z"
    },
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1765266020548,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "hHE0WMnuXtoF",
    "papermill": {
     "duration": 0.013068,
     "end_time": "2025-12-12T10:27:57.454906",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.441838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_loss(func, preds, y):\n",
    "  preds = func(preds)\n",
    "  y = func(y)\n",
    "  return ((preds-y)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0d66fe",
   "metadata": {
    "id": "6l8FFZTOGTG0",
    "papermill": {
     "duration": 0.007945,
     "end_time": "2025-12-12T10:27:57.470846",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.462901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Тренировочный цикл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f17a501",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.487727Z",
     "iopub.status.busy": "2025-12-12T10:27:57.487529Z",
     "iopub.status.idle": "2025-12-12T10:27:57.492161Z",
     "shell.execute_reply": "2025-12-12T10:27:57.491679Z"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1765266020563,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "bBgYODDifzRd",
    "papermill": {
     "duration": 0.014397,
     "end_time": "2025-12-12T10:27:57.493197",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.478800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class LSTMModel(nn.Module):\n",
    "#   def __init__(self\n",
    "#                , mel_bins\n",
    "#                , sequence_length_input\n",
    "#                , sequence_length_output\n",
    "#                , dropout_rate\n",
    "#                , use_bidirectional\n",
    "#                , device=device\n",
    "#                , dtype=torch.float32):\n",
    "#     super().__init__()\n",
    "\n",
    "#     self.mel_bins = mel_bins\n",
    "#     self.sequence_length_input = sequence_length_input\n",
    "#     self.sequence_length_output = sequence_length_output\n",
    "#     self.dropout_rate = dropout_rate\n",
    "#     self.use_bidirectional = use_bidirectional\n",
    "#     self.correction_coef = 1 if not use_bidirectional else 1/2\n",
    "\n",
    "\n",
    "#     self.lstm1 = nn.LSTM(\n",
    "#             input_size=self.sequence_length_input,\n",
    "#             hidden_size=int(self.sequence_length_input*self.correction_coef),\n",
    "#             num_layers=self.mel_bins,\n",
    "#             batch_first=True,\n",
    "#             bidirectional=self.use_bidirectional,\n",
    "#             dropout=self.dropout_rate if self.mel_bins > 1 else 0\n",
    "#             , device=device\n",
    "#             , dtype=dtype\n",
    "#     )\n",
    "#     # self.lstm2 = nn.LSTM(\n",
    "#     #         input_size=self.sequence_length_input,\n",
    "#     #         hidden_size=int(self.sequence_length_input*self.correction_coef),\n",
    "#     #         num_layers=self.mel_bins,\n",
    "#     #         batch_first=True,\n",
    "#     #         bidirectional=self.use_bidirectional,\n",
    "#     #         dropout=self.dropout_rate if self.mel_bins > 1 else 0\n",
    "#     #         , device=device\n",
    "#     #         , dtype=dtype\n",
    "#     # )\n",
    "#     # self.lstm3 = nn.LSTM(\n",
    "#     #         input_size=self.sequence_length_input,\n",
    "#     #         hidden_size=int(self.sequence_length_input*self.correction_coef),\n",
    "#     #         num_layers=self.mel_bins,\n",
    "#     #         batch_first=True,\n",
    "#     #         bidirectional=self.use_bidirectional,\n",
    "#     #         dropout=self.dropout_rate if self.mel_bins > 1 else 0\n",
    "#     #         , device=device\n",
    "#     #         , dtype=dtype\n",
    "#     # )\n",
    "#     self.dropout = nn.Dropout(self.dropout_rate)\n",
    "#     self.final_layer = nn.Linear(self.sequence_length_input\n",
    "#                                  , self.sequence_length_output\n",
    "#                                  , device=device\n",
    "#             , dtype=dtype)\n",
    "\n",
    "#   def _continue(self, X):\n",
    "\n",
    "#     X, (hidden, cell) = self.lstm1(X) # в статье 3 раза lstm\n",
    "#     # X, (hidden, cell) = self.lstm2(X, (hidden, cell))\n",
    "#     # X, (hidden, cell) = self.lstm3(X, (hidden, cell))\n",
    "\n",
    "#     hidden = hidden.view(-1, self.mel_bins, self.sequence_length_input)\n",
    "#     return self.final_layer(X), self.final_layer(hidden)\n",
    "\n",
    "#   def forward(self, X):\n",
    "#     next_seq, hidden = self._continue(X)\n",
    "#     return next_seq, hidden\n",
    "\n",
    "\n",
    "# class BassFromHiddenModel(nn.Module):\n",
    "#   def __init__(self\n",
    "#                , sequence_length_input\n",
    "#                , sequence_length_output\n",
    "#                , device=device\n",
    "#             , dtype=torch.float32):\n",
    "#     super().__init__()\n",
    "#     self.sequence_length_input = sequence_length_input\n",
    "#     self.sequence_length_output = sequence_length_output\n",
    "#     self.bass_parameters = nn.Parameter(torch.rand(self.sequence_length_input\n",
    "#                                                    , self.sequence_length_output\n",
    "#                                                    , device=device, dtype=dtype)\n",
    "#     , requires_grad=True)\n",
    "#     self.lr1 = nn.Linear(self.sequence_length_output\n",
    "#                          , self.sequence_length_output//4\n",
    "#                          , device=device\n",
    "#             , dtype=dtype)\n",
    "#     self.lr2 = nn.Linear(self.sequence_length_output//4\n",
    "#                          , self.sequence_length_output\n",
    "#                          , device=device\n",
    "#             , dtype=dtype)\n",
    "#     self.activ = nn.Sigmoid()\n",
    "\n",
    "#   def forward(self, X):\n",
    "#     return self.lr2(self.activ(self.lr1(X+self.bass_parameters)))\n",
    "\n",
    "\n",
    "# class DrumsFromHiddenModel(nn.Module):\n",
    "#   def __init__(self\n",
    "#                , sequence_length_input\n",
    "#                , sequence_length_output\n",
    "#                , device=device\n",
    "#             , dtype=torch.float32):\n",
    "#     super().__init__()\n",
    "#     self.sequence_length_input = sequence_length_input\n",
    "#     self.sequence_length_output = sequence_length_output\n",
    "#     self.drums_parameters = nn.Parameter(torch.rand(self.sequence_length_input\n",
    "#                                                    , self.sequence_length_output\n",
    "#                                                    , device=device, dtype=dtype)\n",
    "#     , requires_grad=True)\n",
    "#     self.lr1 = nn.Linear(self.sequence_length_output\n",
    "#                          , self.sequence_length_output//4\n",
    "#                          , device=device\n",
    "#             , dtype=dtype)\n",
    "#     self.lr2 = nn.Linear(self.sequence_length_output//4\n",
    "#                          , self.sequence_length_output\n",
    "#                          , device=device\n",
    "#             , dtype=dtype)\n",
    "#     self.activ = nn.Sigmoid()\n",
    "\n",
    "#   def forward(self, X):\n",
    "#     return self.lr2(self.activ(self.lr1(X+self.drums_parameters)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da00ad00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.510417Z",
     "iopub.status.busy": "2025-12-12T10:27:57.510245Z",
     "iopub.status.idle": "2025-12-12T10:27:57.521543Z",
     "shell.execute_reply": "2025-12-12T10:27:57.520872Z"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1765266493438,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "_2H4ML0baVLT",
    "papermill": {
     "duration": 0.021329,
     "end_time": "2025-12-12T10:27:57.522645",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.501316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class BassFromHiddenModel(nn.Module):\n",
    "  def __init__(self\n",
    "               , sequence_length_input\n",
    "               , sequence_length_output\n",
    "               , device=device\n",
    "            , dtype=torch.float32):\n",
    "    super().__init__()\n",
    "    self.sequence_length_input = sequence_length_input\n",
    "    self.sequence_length_output = sequence_length_output\n",
    "    self.bass_parameters = nn.Parameter(torch.rand(self.sequence_length_input\n",
    "                                                   , self.sequence_length_output\n",
    "                                                   , device=device, dtype=dtype)\n",
    "    , requires_grad=True)\n",
    "    self.lr1 = nn.Linear(self.sequence_length_output\n",
    "                         , self.sequence_length_output//4\n",
    "                         , device=device\n",
    "            , dtype=dtype)\n",
    "    self.lr2 = nn.Linear(self.sequence_length_output//4\n",
    "                         , self.sequence_length_output\n",
    "                         , device=device\n",
    "            , dtype=dtype)\n",
    "    self.activ = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, X):\n",
    "    return self.lr2(self.activ(self.lr1(X+self.bass_parameters)))\n",
    "\n",
    "\n",
    "class DrumsFromHiddenModel(nn.Module):\n",
    "  def __init__(self\n",
    "               , sequence_length_input\n",
    "               , sequence_length_output\n",
    "               , device=device\n",
    "            , dtype=torch.float32):\n",
    "    super().__init__()\n",
    "    self.sequence_length_input = sequence_length_input\n",
    "    self.sequence_length_output = sequence_length_output\n",
    "    self.drums_parameters = nn.Parameter(torch.rand(self.sequence_length_input\n",
    "                                                   , self.sequence_length_output\n",
    "                                                   , device=device, dtype=dtype)\n",
    "    , requires_grad=True)\n",
    "    self.lr1 = nn.Linear(self.sequence_length_output\n",
    "                         , self.sequence_length_output//4\n",
    "                         , device=device\n",
    "            , dtype=dtype)\n",
    "    self.lr2 = nn.Linear(self.sequence_length_output//4\n",
    "                         , self.sequence_length_output\n",
    "                         , device=device\n",
    "            , dtype=dtype)\n",
    "    self.activ = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, X):\n",
    "    return self.lr2(self.activ(self.lr1(X+self.drums_parameters)))\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "  def __init__(self\n",
    "               , mel_bins\n",
    "               , sequence_length_input\n",
    "               , sequence_length_output\n",
    "               , dropout_rate\n",
    "               , use_bidirectional\n",
    "               , device=device\n",
    "               , dtype=torch.float32):\n",
    "    super().__init__()\n",
    "\n",
    "    self.mel_bins = mel_bins\n",
    "    self.sequence_length_input = sequence_length_input\n",
    "    self.sequence_length_output = sequence_length_output\n",
    "    self.dropout_rate = dropout_rate\n",
    "    self.use_bidirectional = use_bidirectional\n",
    "    self.correction_coef = 1 if not use_bidirectional else 1/2\n",
    "\n",
    "    # self.bass_model = BassFromHiddenModel(sequence_length_input=config['mel_bins']\n",
    "    #            , sequence_length_output=config['sequence_length_output']).to(device)\n",
    "\n",
    "    # self.drums_model = DrumsFromHiddenModel(sequence_length_input=config['mel_bins']\n",
    "    #            , sequence_length_output=config['sequence_length_output']).to(device)\n",
    "\n",
    "\n",
    "    self.lstm1 = nn.LSTM(\n",
    "            input_size=self.sequence_length_input,\n",
    "            hidden_size=int(self.sequence_length_input*self.correction_coef),\n",
    "            num_layers=self.mel_bins,\n",
    "            batch_first=True,\n",
    "            bidirectional=self.use_bidirectional,\n",
    "            dropout=self.dropout_rate if self.mel_bins > 1 else 0\n",
    "            , device=device\n",
    "            , dtype=dtype\n",
    "    )\n",
    "    self.lstm2 = nn.LSTM(\n",
    "            input_size=self.sequence_length_input,\n",
    "            hidden_size=int(self.sequence_length_input*self.correction_coef),\n",
    "            num_layers=self.mel_bins,\n",
    "            batch_first=True,\n",
    "            bidirectional=self.use_bidirectional,\n",
    "            dropout=self.dropout_rate if self.mel_bins > 1 else 0\n",
    "            , device=device\n",
    "            , dtype=dtype\n",
    "    )\n",
    "    self.lstm3 = nn.LSTM(\n",
    "            input_size=self.sequence_length_input,\n",
    "            hidden_size=int(self.sequence_length_input*self.correction_coef),\n",
    "            num_layers=self.mel_bins,\n",
    "            batch_first=True,\n",
    "            bidirectional=self.use_bidirectional,\n",
    "            dropout=self.dropout_rate if self.mel_bins > 1 else 0\n",
    "            , device=device\n",
    "            , dtype=dtype\n",
    "    )\n",
    "    self.dropout = nn.Dropout(self.dropout_rate)\n",
    "    self.final_layer = nn.Linear(self.sequence_length_input\n",
    "                                 , self.sequence_length_output\n",
    "                                 , device=device\n",
    "            , dtype=dtype)\n",
    "\n",
    "  def _continue(self, X):\n",
    "\n",
    "    next_seq, (hidden, cell) = self.lstm1(X) # в статье 3 раза lstm\n",
    "    bass, _ = self.lstm2(next_seq, (hidden, cell))\n",
    "    drums, _ = self.lstm3(next_seq, (hidden, cell))\n",
    "\n",
    "    # hidden = hidden.view(-1, self.mel_bins, self.sequence_length_input)\n",
    "    return self.final_layer(next_seq), self.final_layer(bass), self.final_layer(drums)\n",
    "\n",
    "  def forward(self, X, batch_size):\n",
    "    next_seq, bass_pred, drums_pred = self._continue(X)\n",
    "    return next_seq, bass_pred[:batch_size], drums_pred[:batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca09782d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.541437Z",
     "iopub.status.busy": "2025-12-12T10:27:57.540906Z",
     "iopub.status.idle": "2025-12-12T10:27:57.543684Z",
     "shell.execute_reply": "2025-12-12T10:27:57.543200Z"
    },
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1765266021090,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "SsDlubVYwTql",
    "papermill": {
     "duration": 0.012703,
     "end_time": "2025-12-12T10:27:57.544711",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.532008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import userdata\n",
    "# import os\n",
    "# os.environ['WANDB_API_KEY'] = userdata.get('WANDB_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e022449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.561794Z",
     "iopub.status.busy": "2025-12-12T10:27:57.561606Z",
     "iopub.status.idle": "2025-12-12T10:27:57.564501Z",
     "shell.execute_reply": "2025-12-12T10:27:57.563948Z"
    },
    "executionInfo": {
     "elapsed": 7546,
     "status": "ok",
     "timestamp": 1765266028647,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "NwsIaAAQxcJC",
    "outputId": "3f081a90-c8a0-48a2-9530-427477e3f74b",
    "papermill": {
     "duration": 0.012837,
     "end_time": "2025-12-12T10:27:57.565578",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.552741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# run = wandb.init(\n",
    "#     project=\"jam-assistant\",\n",
    "#     config=config,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c5feb0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:27:57.582778Z",
     "iopub.status.busy": "2025-12-12T10:27:57.582577Z",
     "iopub.status.idle": "2025-12-12T11:45:53.014859Z",
     "shell.execute_reply": "2025-12-12T11:45:53.014162Z"
    },
    "id": "9nf_KKQzmKPP",
    "papermill": {
     "duration": 4675.451336,
     "end_time": "2025-12-12T11:45:53.024996",
     "exception": false,
     "start_time": "2025-12-12T10:27:57.573660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "reconstruction loss: tensor(2.0336, device='cuda:0')\n",
      "reconstruction loss bass: tensor(1.1451, device='cuda:0')\n",
      "reconstruction loss drums: tensor(1.1385, device='cuda:0')\n",
      "spectral_centroid_loss: tensor(0.0916, device='cuda:0')\n",
      "spectral_bandwidth_loss: tensor(nan, device='cuda:0')\n",
      "spectral_flatness_loss: tensor(nan, device='cuda:0')\n",
      "spectral_entropy_loss: tensor(nan, device='cuda:0')\n",
      "epoch: 1\n",
      "reconstruction loss: tensor(1.8463, device='cuda:0')\n",
      "reconstruction loss bass: tensor(1.1050, device='cuda:0')\n",
      "reconstruction loss drums: tensor(1.0825, device='cuda:0')\n",
      "spectral_centroid_loss: tensor(0.0920, device='cuda:0')\n",
      "spectral_bandwidth_loss: tensor(nan, device='cuda:0')\n",
      "spectral_flatness_loss: tensor(nan, device='cuda:0')\n",
      "spectral_entropy_loss: tensor(nan, device='cuda:0')\n",
      "epoch: 2\n",
      "reconstruction loss: tensor(1.7162, device='cuda:0')\n",
      "reconstruction loss bass: tensor(1.0783, device='cuda:0')\n",
      "reconstruction loss drums: tensor(1.0426, device='cuda:0')\n",
      "spectral_centroid_loss: tensor(0.0991, device='cuda:0')\n",
      "spectral_bandwidth_loss: tensor(nan, device='cuda:0')\n",
      "spectral_flatness_loss: tensor(nan, device='cuda:0')\n",
      "spectral_entropy_loss: tensor(nan, device='cuda:0')\n",
      "epoch: 3\n",
      "reconstruction loss: tensor(1.6006, device='cuda:0')\n",
      "reconstruction loss bass: tensor(1.0533, device='cuda:0')\n",
      "reconstruction loss drums: tensor(0.9999, device='cuda:0')\n",
      "spectral_centroid_loss: tensor(0.0926, device='cuda:0')\n",
      "spectral_bandwidth_loss: tensor(nan, device='cuda:0')\n",
      "spectral_flatness_loss: tensor(nan, device='cuda:0')\n",
      "spectral_entropy_loss: tensor(nan, device='cuda:0')\n",
      "epoch: 4\n",
      "reconstruction loss: tensor(1.4929, device='cuda:0')\n",
      "reconstruction loss bass: tensor(1.0301, device='cuda:0')\n",
      "reconstruction loss drums: tensor(0.9644, device='cuda:0')\n",
      "spectral_centroid_loss: tensor(0.1033, device='cuda:0')\n",
      "spectral_bandwidth_loss: tensor(nan, device='cuda:0')\n",
      "spectral_flatness_loss: tensor(nan, device='cuda:0')\n",
      "spectral_entropy_loss: tensor(nan, device='cuda:0')\n",
      "epoch: 5\n",
      "reconstruction loss: tensor(1.3941, device='cuda:0')\n",
      "reconstruction loss bass: tensor(1.0086, device='cuda:0')\n",
      "reconstruction loss drums: tensor(0.9272, device='cuda:0')\n",
      "spectral_centroid_loss: tensor(0.0905, device='cuda:0')\n",
      "spectral_bandwidth_loss: tensor(nan, device='cuda:0')\n",
      "spectral_flatness_loss: tensor(nan, device='cuda:0')\n",
      "spectral_entropy_loss: tensor(nan, device='cuda:0')\n",
      "epoch: 6\n",
      "reconstruction loss: tensor(1.3049, device='cuda:0')\n",
      "reconstruction loss bass: tensor(0.9888, device='cuda:0')\n",
      "reconstruction loss drums: tensor(0.8969, device='cuda:0')\n",
      "spectral_centroid_loss: tensor(0.1145, device='cuda:0')\n",
      "spectral_bandwidth_loss: tensor(nan, device='cuda:0')\n",
      "spectral_flatness_loss: tensor(nan, device='cuda:0')\n",
      "spectral_entropy_loss: tensor(nan, device='cuda:0')\n",
      "epoch: 7\n",
      "reconstruction loss: tensor(1.2396, device='cuda:0')\n",
      "reconstruction loss bass: tensor(0.9646, device='cuda:0')\n",
      "reconstruction loss drums: tensor(0.8730, device='cuda:0')\n",
      "spectral_centroid_loss: tensor(0.1257, device='cuda:0')\n",
      "spectral_bandwidth_loss: tensor(nan, device='cuda:0')\n",
      "spectral_flatness_loss: tensor(nan, device='cuda:0')\n",
      "spectral_entropy_loss: tensor(nan, device='cuda:0')\n",
      "epoch: 8\n",
      "reconstruction loss: tensor(1.2484, device='cuda:0')\n",
      "reconstruction loss bass: tensor(0.9166, device='cuda:0')\n",
      "reconstruction loss drums: tensor(0.8425, device='cuda:0')\n",
      "spectral_centroid_loss: tensor(0.1171, device='cuda:0')\n",
      "spectral_bandwidth_loss: tensor(nan, device='cuda:0')\n",
      "spectral_flatness_loss: tensor(nan, device='cuda:0')\n",
      "spectral_entropy_loss: tensor(nan, device='cuda:0')\n",
      "epoch: 9\n",
      "reconstruction loss: tensor(1.1957, device='cuda:0')\n",
      "reconstruction loss bass: tensor(0.9139, device='cuda:0')\n",
      "reconstruction loss drums: tensor(0.8391, device='cuda:0')\n",
      "spectral_centroid_loss: tensor(0.1102, device='cuda:0')\n",
      "spectral_bandwidth_loss: tensor(nan, device='cuda:0')\n",
      "spectral_flatness_loss: tensor(nan, device='cuda:0')\n",
      "spectral_entropy_loss: tensor(nan, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(mel_bins=config['mel_bins']\n",
    "               , sequence_length_input=config['sequence_length_input']\n",
    "               , sequence_length_output=config['sequence_length_output']\n",
    "               , dropout_rate=config['dropout_rate']\n",
    "               , use_bidirectional=config['use_bidirectional']).to(device)\n",
    "# bass_model = BassFromHiddenModel(sequence_length_input=config['mel_bins']\n",
    "#                , sequence_length_output=config['sequence_length_output']).to(device)\n",
    "# drums_model = DrumsFromHiddenModel(sequence_length_input=config['mel_bins']\n",
    "#                , sequence_length_output=config['sequence_length_output']).to(device)\n",
    "learning_rate = config['learning_rate']\n",
    "optim = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "melspec = T.MelSpectrogram(config['target_sample_rate']\n",
    "                           , n_fft=config['n_fft']\n",
    "                           , n_mels=config['mel_bins']\n",
    "                           , hop_length=config['hop_length']).to(device)\n",
    "\n",
    "# optim_bass = torch.optim.RMSprop(bass_model.parameters(), lr=learning_rate)\n",
    "# optim_drums = torch.optim.RMSprop(drums_model.parameters(), lr=learning_rate)\n",
    "num_epochs = config['num_epochs']\n",
    "scaler = torch.amp.GradScaler(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "  optim.zero_grad()\n",
    "\n",
    "\n",
    "  for batch in mus_dl_train:\n",
    "\n",
    "    # сначала учим генерировать продолжение\n",
    "    with torch.autocast(device_type=device\n",
    "                        , dtype=torch.float16):\n",
    "\n",
    "      vocals_X, vocals_y =  batch['vocals']\n",
    "      drums_X, drums_y = batch['drums']\n",
    "      bass_X, bass_y = batch['bass']\n",
    "      other_X, other_y = batch['other']\n",
    "      all_X, all_y = batch['other']\n",
    "\n",
    "      samples_in_batch = vocals_X.shape[0]\n",
    "\n",
    "      stems_X = torch.cat([vocals_X, drums_X, bass_X, other_X], dim=0).to(device)\n",
    "      stems_y = torch.cat([vocals_y, drums_y, bass_y, other_y], dim=0).to(device)\n",
    "\n",
    "      del vocals_X\n",
    "      del vocals_y\n",
    "      del drums_X\n",
    "      del drums_y\n",
    "      del bass_X\n",
    "      del bass_y\n",
    "      del other_X\n",
    "      del other_y\n",
    "      del all_X\n",
    "      del all_y\n",
    "\n",
    "      melspecs_X = melspec(stems_X)\n",
    "      melspecs_y = melspec(stems_y)\n",
    "\n",
    "      if config['target_log']:\n",
    "        melspecs_X = torch.log1p(melspecs_X)\n",
    "        melspecs_y = torch.log1p(melspecs_y)\n",
    "\n",
    "      melspecs_pred, melspecs_pred_bass, melspecs_pred_drums = model(melspecs_X, batch_size=samples_in_batch)\n",
    "      # hidden = hidden[:samples_in_batch]\n",
    "      # melspecs_pred_bass = bass_model(hidden)\n",
    "      # melspecs_pred_drums = drums_model(hidden)\n",
    "\n",
    "      if config['target_log']:\n",
    "        melspecs_pred = torch.expm1(melspecs_pred)\n",
    "        melspecs_pred_bass = torch.expm1(melspecs_pred_bass)\n",
    "        melspecs_pred_drums = torch.expm1(melspecs_pred_drums)\n",
    "\n",
    "      normalized_pred = normalize(melspecs_pred)\n",
    "      normalized_bass_pred = normalize(melspecs_pred_bass)\n",
    "      normalized_drums_pred = normalize(melspecs_pred_drums)\n",
    "      normalized_y = normalize(melspecs_y)\n",
    "\n",
    "      # без нормализации - гигантские значения лосса\n",
    "\n",
    "      reconstruction_loss = ((normalized_pred-normalized_y)**2).sum()\n",
    "      reconstruction_loss_without_normalization = (\n",
    "          (melspecs_pred-melspecs_y)**2\n",
    "          ).mean()\n",
    "\n",
    "      spectral_centroid_loss = calc_loss(spectral_centroid_fn\n",
    "                                        , melspecs_pred\n",
    "                                        , melspecs_y)\n",
    "      # spectral_bandwidth_loss = calc_loss(spectral_bandwidth_fn\n",
    "      #                                     , melspecs_pred\n",
    "      #                                     , melspecs_y)\n",
    "      # spectral_flatness_loss = calc_loss(spectral_flatness_fn\n",
    "      #                                   , melspecs_pred\n",
    "      #                                   , melspecs_y)\n",
    "      # spectral_entropy_loss = calc_loss(spectral_entropy_fn\n",
    "      #                                   , melspecs_pred\n",
    "      #                                   , melspecs_y)\n",
    "\n",
    "      reconstruction_loss_bass = ((normalized_bass_pred-normalized_y[samples_in_batch*2:samples_in_batch*3])**2).sum()\n",
    "      reconstruction_loss_drums = ((normalized_drums_pred\\\n",
    "                                    -normalized_y[samples_in_batch*1:samples_in_batch*2])**2).sum()\n",
    "      # run.log({'reconstruction_loss_train':reconstruction_loss,\n",
    "              #  'reconstruction_loss_bass_train':reconstruction_loss_bass,\n",
    "              #  'reconstruction_loss_drums_train':reconstruction_loss_drums})\n",
    "\n",
    "\n",
    "\n",
    "    scaler.scale(reconstruction_loss).backward(retain_graph=True)\n",
    "    scaler.scale(reconstruction_loss_bass).backward(retain_graph=True)\n",
    "    scaler.scale(reconstruction_loss_drums).backward(retain_graph=True)\n",
    "\n",
    "    \n",
    "    # reconstruction_loss.backward(retain_graph=True)\n",
    "    # reconstruction_loss_bass.backward(retain_graph=True)\n",
    "    # reconstruction_loss_drums.backward(retain_graph=True)\n",
    "\n",
    "    if config['spectral_backward']:\n",
    "      scaler.scale(spectral_centroid_loss).backward(retain_graph=True)\n",
    "    #   spectral_bandwidth_loss.backward(retain_graph=True)\n",
    "    #   spectral_flatness_loss.backward(retain_graph=True)\n",
    "    #   spectral_entropy_loss.backward(retain_graph=True)\n",
    "  scaler.step(optim)\n",
    "  # scaler.step(optim_bass)\n",
    "  # scaler.step(optim_drums)\n",
    "\n",
    "  scaler.update()\n",
    "  with torch.no_grad():\n",
    "    del batch\n",
    "    del stems_X\n",
    "    del stems_y\n",
    "    del melspecs_X\n",
    "    del melspecs_y\n",
    "    del melspecs_pred\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "  # optim.step()\n",
    "  # optim_bass.step()\n",
    "  # optim_drums.step()\n",
    "    # break\n",
    "\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    with torch.autocast(device_type=device\n",
    "                    , dtype=torch.float16):\n",
    "      tmp_losses = {'reconstruction_loss':[]\n",
    "                    , 'reconstruction_loss_bass':[]\n",
    "                    , 'reconstruction_loss_drums':[]\n",
    "                    , 'spectral_centroid_loss':[]\n",
    "                    , 'spectral_bandwidth_loss':[]\n",
    "                    , 'spectral_flatness_loss':[]\n",
    "                    , 'spectral_entropy_loss':[]}\n",
    "      for batch in mus_dl_test:\n",
    "        vocals_X, vocals_y =  batch['vocals']\n",
    "        drums_X, drums_y = batch['drums']\n",
    "        bass_X, bass_y = batch['bass']\n",
    "        other_X, other_y = batch['other']\n",
    "        all_X, all_y = batch['other']\n",
    "\n",
    "        stems_X = torch.cat([vocals_X, drums_X, bass_X, other_X], dim=0).to(device)\n",
    "        stems_y = torch.cat([vocals_y, drums_y, bass_y, other_y], dim=0).to(device)\n",
    "\n",
    "        samples_in_batch = vocals_X.shape[0]\n",
    "\n",
    "        melspecs_X = melspec(stems_X)\n",
    "        melspecs_y = melspec(stems_y)\n",
    "        if config['target_log']:\n",
    "          melspecs_X = torch.log1p(melspecs_X)\n",
    "          melspecs_y = torch.log1p(melspecs_y)\n",
    "\n",
    "        melspecs_pred, melspecs_pred_bass, melspecs_pred_drums = model(melspecs_X, batch_size=samples_in_batch)\n",
    "        # hidden = hidden[:vocals_X.shape[0]]\n",
    "        # melspecs_pred_bass = bass_model(hidden)\n",
    "        # melspecs_pred_drums = drums_model(hidden)\n",
    "\n",
    "        if config['target_log']:\n",
    "          melspecs_pred = torch.expm1(melspecs_pred)\n",
    "          melspecs_pred_bass = torch.expm1(melspecs_pred_bass)\n",
    "          melspecs_pred_drums = torch.expm1(melspecs_pred_drums)\n",
    "\n",
    "        normalized_pred = normalize(melspecs_pred)\n",
    "        normalized_bass_pred = normalize(melspecs_pred_bass)\n",
    "        normalized_drums_pred = normalize(melspecs_pred_drums)\n",
    "        normalized_y = normalize(melspecs_y)\n",
    "\n",
    "        # без нормализации - гигантские значения лосса\n",
    "        reconstruction_loss = ((normalized_pred-normalized_y)**2).sum()\n",
    "        reconstruction_loss_without_normalization = (\n",
    "            (melspecs_pred-melspecs_y)**2\n",
    "            ).mean()\n",
    "\n",
    "        spectral_centroid_loss = calc_loss(spectral_centroid_fn\n",
    "                                          , melspecs_pred\n",
    "                                          , melspecs_y)\n",
    "        spectral_bandwidth_loss = calc_loss(spectral_bandwidth_fn\n",
    "                                            , melspecs_pred\n",
    "                                            , melspecs_y)\n",
    "        spectral_flatness_loss = calc_loss(spectral_flatness_fn\n",
    "                                          , melspecs_pred\n",
    "                                          , melspecs_y)\n",
    "        spectral_entropy_loss = calc_loss(spectral_entropy_fn\n",
    "                                          , melspecs_pred\n",
    "                                          , melspecs_y)\n",
    "\n",
    "        reconstruction_loss_bass = ((normalized_bass_pred-normalized_y[bass_X.shape[0]*2:bass_X.shape[0]*3])**2).sum()\n",
    "        reconstruction_loss_drums = ((normalized_drums_pred-normalized_y[drums_X.shape[0]*1:bass_X.shape[0]*2])**2).sum()\n",
    "\n",
    "        tmp_losses['reconstruction_loss'].append(reconstruction_loss)\n",
    "        tmp_losses['reconstruction_loss_bass'].append(reconstruction_loss_bass)\n",
    "        tmp_losses['reconstruction_loss_drums'].append(reconstruction_loss_drums)\n",
    "        tmp_losses['spectral_centroid_loss'].append(spectral_centroid_loss)\n",
    "        tmp_losses['spectral_bandwidth_loss'].append(spectral_bandwidth_loss)\n",
    "        tmp_losses['spectral_flatness_loss'].append(spectral_flatness_loss)\n",
    "        tmp_losses['spectral_entropy_loss'].append(spectral_entropy_loss)\n",
    "\n",
    "        del batch\n",
    "        del stems_X\n",
    "        del stems_y\n",
    "        del melspecs_X\n",
    "        del melspecs_y\n",
    "        del vocals_X\n",
    "        del vocals_y\n",
    "        del drums_X\n",
    "        del drums_y\n",
    "        del bass_X\n",
    "        del bass_y\n",
    "        del other_X\n",
    "        del other_y\n",
    "        del all_X\n",
    "        del all_y\n",
    "        del melspecs_pred\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "  print('epoch:', epoch)\n",
    "  print('reconstruction loss:', sum(tmp_losses['reconstruction_loss'])/len(tmp_losses['reconstruction_loss']))\n",
    "  print('reconstruction loss bass:', sum(tmp_losses['reconstruction_loss_bass'])/len(tmp_losses['reconstruction_loss_bass']))\n",
    "  print('reconstruction loss drums:', sum(tmp_losses['reconstruction_loss_drums'])/len(tmp_losses['reconstruction_loss_drums']))\n",
    "  print('spectral_centroid_loss:', sum(tmp_losses['spectral_centroid_loss'])/len(tmp_losses['spectral_centroid_loss']))\n",
    "  print('spectral_bandwidth_loss:', sum(tmp_losses['spectral_bandwidth_loss'])/len(tmp_losses['spectral_bandwidth_loss']))\n",
    "  print('spectral_flatness_loss:', sum(tmp_losses['spectral_flatness_loss'])/len(tmp_losses['spectral_flatness_loss']))\n",
    "  print('spectral_entropy_loss:', sum(tmp_losses['spectral_entropy_loss'])/len(tmp_losses['spectral_entropy_loss']))\n",
    "  # run.log(tmp_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e4c710d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:45:53.043372Z",
     "iopub.status.busy": "2025-12-12T11:45:53.043038Z",
     "iopub.status.idle": "2025-12-12T11:45:54.070329Z",
     "shell.execute_reply": "2025-12-12T11:45:54.069676Z"
    },
    "papermill": {
     "duration": 1.038101,
     "end_time": "2025-12-12T11:45:54.071747",
     "exception": false,
     "start_time": "2025-12-12T11:45:53.033646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with torch.no_grad():\n",
    "    torch.save(model.state_dict(), '/kaggle/working/lstm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ee56fe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T11:45:54.091280Z",
     "iopub.status.busy": "2025-12-12T11:45:54.090679Z",
     "iopub.status.idle": "2025-12-12T11:45:54.093883Z",
     "shell.execute_reply": "2025-12-12T11:45:54.093379Z"
    },
    "executionInfo": {
     "elapsed": 372426,
     "status": "aborted",
     "timestamp": 1765266337139,
     "user": {
      "displayName": "Oleg Papulov",
      "userId": "14061711875176842236"
     },
     "user_tz": -180
    },
    "id": "eeK1t-WW-Ttn",
    "papermill": {
     "duration": 0.013892,
     "end_time": "2025-12-12T11:45:54.094871",
     "exception": false,
     "start_time": "2025-12-12T11:45:54.080979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "\n",
    "# понять, почему спектральные метрики скатываются в nan?\n",
    "# как можно объединить расчёт loss восстановленных и спектральных?\n",
    "# код в более промышленном варианте - сделать функцию чтобы считать для каждого отдельно набора стемов и спектральные и реконструкцию\n",
    "# попробовать восстановить звук из мелки\n",
    "# расширить датасет"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4710.492234,
   "end_time": "2025-12-12T11:45:55.723664",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-12T10:27:25.231430",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
